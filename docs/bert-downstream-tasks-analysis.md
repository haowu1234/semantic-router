# BERT 下游任务与 Semantic Router 扩展方案分析

> 本文档包含两部分：
> 1. BERT 下游任务输出头设计的形象化理解
> 2. Semantic Router 项目中 BERT 的潜在应用场景分析

---

## 目录

- [第一部分：BERT 下游任务输出头设计](#第一部分bert-下游任务输出头设计)
  - [1. BERT 整体架构比喻](#1-bert-整体架构比喻)
  - [2. 文本分类任务](#2-文本分类任务-sequence-classification)
  - [3. Token 分类任务](#3-token-分类任务-token-classificationner)
  - [4. 问答系统任务](#4-问答系统任务-question-answering)
  - [5. 句子对关系任务](#5-句子对关系任务-sentence-pair-classification)
  - [6. 输出头设计对比总结](#6-输出头设计对比总结)
- [第二部分：Semantic Router BERT 扩展方案](#第二部分semantic-router-bert-扩展方案)
  - [现有 BERT 应用](#现有-bert-应用)
  - [潜在扩展场景](#潜在扩展场景)
  - [优先级建议](#优先级建议)

---

# 第一部分：BERT 下游任务输出头设计

## 1. BERT 整体架构比喻

把 BERT 想象成一个「万能翻译公司」：

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                           BERT：万能翻译公司                                   │
│                                                                               │
│   输入：一句话的每个词                                                          │
│   ┌─────┬─────┬─────┬─────┬─────┬─────┬─────┐                                │
│   │[CLS]│  我  │  的  │ 邮箱 │  是  │john@│.com │                              │
│   └──┬──┴──┬──┴──┬──┴──┬──┴──┬──┴──┬──┴──┬──┘                                │
│      │     │     │     │     │     │     │                                    │
│      ▼     ▼     ▼     ▼     ▼     ▼     ▼                                    │
│   ┌──────────────────────────────────────────┐                               │
│   │        12层 Transformer 编码器            │  ← BERT 的「理解部门」          │
│   │        （理解上下文、语义关系）             │                                │
│   └──────────────────────────────────────────┘                               │
│      │     │     │     │     │     │     │                                    │
│      ▼     ▼     ▼     ▼     ▼     ▼     ▼                                    │
│   ┌─────┬─────┬─────┬─────┬─────┬─────┬─────┐                                │
│   │ h₀  │ h₁  │ h₂  │ h₃  │ h₄  │ h₅  │ h₆  │  ← 每个词的「理解报告」(768维)  │
│   └─────┴─────┴─────┴─────┴─────┴─────┴─────┘                                │
│                                                                               │
│   🎯 关键：BERT 本身只负责「理解」，不做最终决策                                 │
│   🎯 最终决策由「专门的输出头」来完成                                            │
└──────────────────────────────────────────────────────────────────────────────┘
```

**核心洞察**：
- BERT 编码器 = 一个读完书、理解透彻的学霸
- 输出头 = 学霸面前的选择题答题卡（A/B/C/D 打勾就行）

---

## 2. 文本分类任务 (Sequence Classification)

**比喻**：给整篇文章贴一个标签

**场景**：判断一封邮件是「垃圾邮件」还是「正常邮件」

```
┌────────────────────────────────────────────────────────────────┐
│  输入: "恭喜您中奖了！请点击链接领取..."                           │
└────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌────────────────────────────────────────────────────────────────┐
│                      BERT 编码器                                │
│                     （理解整句话）                               │
└────────────────────────────────────────────────────────────────┘
                              │
     ┌────────────────────────┼────────────────────────┐
     │                        │                        │
     ▼                        ▼                        ▼
   [CLS]                    词1                      词N
  ┌─────┐                 ┌─────┐                 ┌─────┐
  │ h₀  │                 │ h₁  │      ...       │ hₙ  │
  └──┬──┘                 └─────┘                 └─────┘
     │                       ❌                      ❌
     │                   (不用这些)               (不用这些)
     │
     │  ✅ 只用 [CLS] 的输出！
     │     因为 [CLS] 是「整句话的摘要代表」
     │
     ▼
┌──────────────────────┐
│   分类输出头          │  ← 一个简单的全连接层
│   Linear(768 → 2)    │     768维 → 2个类别
└──────────────────────┘
     │
     ▼
  ┌─────────────────┐
  │ 垃圾邮件: 0.95  │
  │ 正常邮件: 0.05  │
  └─────────────────┘
```

**💡 核心思想**：用「班长」([CLS]) 代表全班的意见

### 代码实现

```python
class BertForSequenceClassification(nn.Module):
    def __init__(self, bert, num_labels):
        self.bert = bert
        # 输出头：只需要一个线性层
        self.classifier = nn.Linear(768, num_labels)
    
    def forward(self, input_ids):
        outputs = self.bert(input_ids)
        # 🎯 关键：只取 [CLS] 的输出 (第0个位置)
        cls_output = outputs.last_hidden_state[:, 0, :]  # shape: [batch, 768]
        logits = self.classifier(cls_output)  # shape: [batch, num_labels]
        return logits
```

---

## 3. Token 分类任务 (Token Classification/NER)

**比喻**：给每个词贴标签

**场景**：标注句子中的人名、地点、组织（或 PII 信息）

```
┌────────────────────────────────────────────────────────────────┐
│  输入: "张三 在 北京 的 腾讯 工作"                                │
└────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌────────────────────────────────────────────────────────────────┐
│                      BERT 编码器                                │
└────────────────────────────────────────────────────────────────┘
                              │
     ┌────────┬────────┬────────┬────────┬────────┬────────┐
     ▼        ▼        ▼        ▼        ▼        ▼        ▼
  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐
  │[CLS]│  │ 张三 │  │  在  │  │ 北京 │  │  的  │  │ 腾讯 │  │ 工作 │
  │ h₀  │  │ h₁  │  │ h₂  │  │ h₃  │  │ h₄  │  │ h₅  │  │ h₆  │
  └──┬──┘  └──┬──┘  └──┬──┘  └──┬──┘  └──┬──┘  └──┬──┘  └──┬──┘
     │        │        │        │        │        │        │
     │        ▼        ▼        ▼        ▼        ▼        ▼
     │     ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐
     ❌    │ 768 │  │ 768 │  │ 768 │  │ 768 │  │ 768 │  │ 768 │
  (不用)   │  ↓  │  │  ↓  │  │  ↓  │  │  ↓  │  │  ↓  │  │  ↓  │
           │  7  │  │  7  │  │  7  │  │  7  │  │  7  │  │  7  │
           └──┬──┘  └──┬──┘  └──┬──┘  └──┬──┘  └──┬──┘  └──┬──┘
              │        │        │        │        │        │
              ▼        ▼        ▼        ▼        ▼        ▼
           B-PER      O      B-LOC      O      B-ORG      O
           (人名)   (普通)   (地点)   (普通)   (组织)   (普通)
```

**💡 核心思想**：每个学生都要交自己的作业（每个词都要分类）

### BIO 标注方案

| 标签前缀 | 含义 | 示例 |
|---------|------|------|
| `B-XXX` | PII 实体的**开始**（Beginning） | B-PERSON |
| `I-XXX` | PII 实体的**内部**（Inside） | I-PERSON |
| `O` | 非 PII 词（Outside） | O |

### 代码实现

```python
class BertForTokenClassification(nn.Module):
    def __init__(self, bert, num_labels):  # num_labels = 7 (B-PER, I-PER, B-LOC, ...)
        self.bert = bert
        # 输出头：给每个 token 分类
        self.classifier = nn.Linear(768, num_labels)
    
    def forward(self, input_ids):
        outputs = self.bert(input_ids)
        # 🎯 关键：取所有 token 的输出
        sequence_output = outputs.last_hidden_state  # shape: [batch, seq_len, 768]
        logits = self.classifier(sequence_output)    # shape: [batch, seq_len, num_labels]
        return logits  # 每个位置都有一个标签预测
```

### PII 检测为什么用 Token Classification？

因为 PII 检测需要：
1. 找出「哪些词」是敏感信息 → 需要给每个词打标签
2. 知道「是什么类型」的敏感信息 → 标签包含类型信息 (B-EMAIL, B-PHONE...)
3. 知道「精确边界」在哪里 → BIO 标注能准确定位实体边界

---

## 4. 问答系统任务 (Question Answering)

**比喻**：在文章中用荧光笔划出答案

**场景**：给定问题和段落，找出答案的起始和结束位置

```
问题：「腾讯的总部在哪里？」
段落：「腾讯是一家中国科技公司，总部位于深圳，由马化腾创立。」

┌────────────────────────────────────────────────────────────────┐
│  输入: [CLS] 腾讯的总部在哪里？[SEP] 腾讯是一家...深圳...创立。  │
└────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌────────────────────────────────────────────────────────────────┐
│                      BERT 编码器                                │
└────────────────────────────────────────────────────────────────┘
                              │
     ┌────────┬────────┬────────┬────────┬────────┬────────┐
     ▼        ▼        ▼        ▼        ▼        ▼        ▼
  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐
  │ h₀  │  │ h₁  │  │ ... │  │ h₈  │  │ h₉  │  │ ... │  │ hₙ  │
  └─────┘  └─────┘  └─────┘  └──┬──┘  └──┬──┘  └─────┘  └─────┘
                               │        │
                    ┌──────────┴────────┴──────────┐
                    │      两个分类头（共享输入）     │
                    │   Start Head    End Head     │
                    │   (768→1)       (768→1)      │
                    └──────────┬────────┬──────────┘
                               │        │
                               ▼        ▼
                    位置 8 得分最高   位置 9 得分最高
                         ↓              ↓
                       「深圳」      (深圳的结尾)

                    答案 = 段落[8:9] = "深圳" ✅
```

**💡 核心思想**：两个「探测器」分别找答案的「头」和「尾」

### 代码实现

```python
class BertForQuestionAnswering(nn.Module):
    def __init__(self, bert):
        self.bert = bert
        # 输出头：两个分数（开始位置、结束位置）
        self.qa_outputs = nn.Linear(768, 2)  # 输出 2 个分数
    
    def forward(self, input_ids):
        outputs = self.bert(input_ids)
        sequence_output = outputs.last_hidden_state  # [batch, seq_len, 768]
        
        # 每个位置输出 2 个分数
        logits = self.qa_outputs(sequence_output)    # [batch, seq_len, 2]
        
        # 🎯 关键：拆分成开始分数和结束分数
        start_logits = logits[:, :, 0]  # [batch, seq_len] - 每个位置的「开始」得分
        end_logits = logits[:, :, 1]    # [batch, seq_len] - 每个位置的「结束」得分
        
        return start_logits, end_logits
```

---

## 5. 句子对关系任务 (Sentence Pair Classification)

**比喻**：判断两句话的关系

**场景**：判断两句话是「矛盾」「蕴含」还是「中立」

```
句子A：「一只狗在草地上跑」
句子B：「一只动物在户外活动」

┌────────────────────────────────────────────────────────────────┐
│  输入: [CLS] 一只狗在草地上跑 [SEP] 一只动物在户外活动 [SEP]     │
└────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌────────────────────────────────────────────────────────────────┐
│                      BERT 编码器                                │
│           （自动学习两句话之间的关系）                            │
└────────────────────────────────────────────────────────────────┘
                              │
                              ▼
                          [CLS] 的输出
                           ┌─────┐
                           │ h₀  │ ← 包含了两句话关系的信息
                           └──┬──┘
                              │
                              ▼
                    ┌──────────────────┐
                    │ Linear(768 → 3)  │
                    └──────────────────┘
                              │
                              ▼
                    ┌──────────────────┐
                    │ 蕴含: 0.85 ✅    │
                    │ 矛盾: 0.05       │
                    │ 中立: 0.10       │
                    └──────────────────┘
```

**💡 核心思想**：和文本分类一样，但输入是两句话拼接

---

## 6. 输出头设计对比总结

| 任务 | 用哪些输出 | 输出头设计 |
|------|-----------|-----------|
| **文本分类**（情感分析） | 只用 [CLS] | `Linear(768 → num_classes)` |
| **Token 分类**（NER/PII） | 用每个 Token | `Linear(768 → num_labels)` 应用到每个位置 |
| **问答系统** | 用每个 Token | `Linear(768 → 2)` 输出 start/end 位置分数 |
| **句子对关系**（NLI） | 只用 [CLS] | `Linear(768 → 3)` 蕴含/矛盾/中立 |

### 为什么输出头这么简单？

BERT 的「重活」都在编码器里做了：
- 理解词义（"苹果" 是水果还是公司？）
- 理解语法（主谓宾关系）
- 理解上下文（代词指代谁？）
- 理解语义关系（这两句话矛不矛盾？）

输出头只需要做「最后一步决策」：把 768 维的「理解结果」映射到具体的「类别数量」

---

# 第二部分：Semantic Router BERT 扩展方案

## 现有 BERT 应用

| 任务 | 使用的模型 | 输出头类型 |
|------|-----------|-----------|
| 意图/领域分类 | BERT, ModernBERT, mmBERT-32K | 序列分类 |
| PII 检测 | BERT (Token Classification) | Token 分类 |
| Jailbreak 检测 | BERT, ModernBERT | 序列分类 |
| 用户满意度分类 | mmBERT (4类) | 序列分类 |
| 双任务分类器 | DistilBERT | 序列分类 + Token 分类 |
| 事实核查 | BERT with LoRA | 序列分类 |
| 语义嵌入 | Qwen3-Embedding, GemmaEmbedding | 嵌入提取 |

---

## 潜在扩展场景

### 1. 查询改写与扩展 (Query Rewriting & Expansion)

**场景**：用户的问题可能表述不清或过于简略

```
原始查询: "Python 怎么读文件"
                    │
                    ▼
          ┌─────────────────┐
          │  Query Rewriter │ ← BERT 序列分类 + 模板
          └────────┬────────┘
                   │
                   ▼
改写后: "如何使用 Python 读取文本文件？请提供多种方法及其适用场景"
```

**BERT 任务类型**：
- 序列分类：判断查询是否需要改写 (清晰/模糊/需扩展)
- Token 分类：识别查询中的关键实体和意图词
- 句子对分类：原始查询与改写后查询的语义一致性验证

**价值**：提升下游 LLM 的回答质量，减少用户追问次数

---

### 2. 提示词质量评估 (Prompt Quality Assessment)

**场景**：在路由之前评估用户提示词的质量

```
用户提示词 ──────────────────────────────┐
                                        │
                                        ▼
                           ┌─────────────────────┐
                           │  Prompt Quality     │
                           │  Classifier         │
                           │  (BERT 多标签分类)  │
                           └──────────┬──────────┘
                                      │
     ┌────────────┬────────────┬──────┼──────┬────────────┐
     ▼            ▼            ▼      ▼      ▼            ▼
┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐
│ 清晰度  │ │ 完整度  │ │ 可执行性│ │ 安全性  │ │ 复杂度  │
│ 0.92   │ │ 0.45 ⚠️│ │ 0.88    │ │ 0.95   │ │ 0.72   │
└─────────┘ └─────────┘ └─────────┘ └─────────┘ └─────────┘
                 │
                 └──────────┐
                            ▼
           ⚠️ 完整度低 → 触发「引导补全」流程
```

**输出头**：多标签分类 `Linear(768 → 5) + Sigmoid`

**价值**：主动引导用户提供更好的提示词

---

### 3. 响应质量预评估 (Response Quality Pre-Assessment)

**场景**：在返回给用户之前，评估 LLM 响应的质量

```
评估维度:
┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐
│ 相关性  │ │ 完整性  │ │ 准确性  │ │ 有用性  │ │ 安全性  │
│ 0.95   │ │ 0.88   │ │ 0.72 ⚠️│ │ 0.91   │ │ 0.99   │
└─────────┘ └─────────┘ └─────────┘ └─────────┘ └─────────┘
                              │
                              └──────┐
                                     ▼
                  准确性偏低 → 触发「二次验证」或路由到更强模型
```

**价值**：自动质量把关，低质量响应自动重试或升级

---

### 4. 语义压缩与去重 (Semantic Compression & Deduplication)

**场景**：长对话历史导致 token 超限，需要智能压缩

```
长对话历史 (10000 tokens)
          │
          ▼
┌─────────────────────┐
│  Semantic Compressor │
│  (BERT + 聚类)       │
└──────────┬──────────┘
           │
┌──────────┼──────────┬──────────┐
▼          ▼          ▼          ▼
重要性    相似度      时效性
评分      去重        权重
           │
           ▼
压缩后 (2000 tokens)
```

**BERT 任务**：
- 句子重要性评分 (回归任务)
- 句子相似度计算 (去重)
- 关键信息抽取 (Token 分类)

**价值**：突破上下文长度限制，保持对话连贯性

---

### 5. 多轮对话理解与意图追踪 (Multi-turn Intent Tracking)

**场景**：跨轮次理解用户的真实意图

```
Turn 1: "我想了解一下机器学习"         意图: 信息获取 (泛)
Turn 2: "有什么好的入门资源吗"         意图: 资源推荐
Turn 3: "我是学 Python 的"             意图: 背景补充
Turn 4: "有没有实战项目"               意图: 项目推荐
Turn 5: "就用图像分类的"               意图: 具体化 (指代消解)
          │
          ▼
┌─────────────────────┐
│  Multi-turn Intent  │
│  Tracker (BERT)     │
└──────────┬──────────┘
           │
           ▼
综合意图分析:
• 主意图: Python 机器学习实战学习
• 子意图: 图像分类项目
• 用户画像: Python 开发者、ML 初学者
• 推荐路由: 教程类模型 + 代码生成能力强的模型
```

**BERT 任务**：
- 意图分类 (每轮)
- 指代消解 (Token 分类)
- 意图融合 (句子对分类)

**价值**：更精准的路由决策，提升多轮对话体验

---

### 6. 毒性与情感检测 (Toxicity & Sentiment Detection)

**场景**：检测用户输入或模型输出中的负面/有害内容

```
检测维度:
┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐
│ 侮辱 │ │ 威胁 │ │ 仇恨 │ │ 色情 │ │ 歧视 │ │ 负面 │ │ 讽刺 │
│ 0.12│ │ 0.05│ │ 0.08│ │ 0.02│ │ 0.15│ │ 0.78│ │ 0.45│
└──────┘ └──────┘ └──────┘ └──────┘ └──────┘ └──────┘ └──────┘
                                         │       │
                        ┌────────────────┴───────┘
                        ▼
         检测到负面情绪 + 讽刺语气
         → 路由到「情感支持」类模型
         → 或触发「安抚话术」前缀
```

**价值**：更细粒度的内容审核，与现有 Jailbreak 检测互补

---

### 7. 知识边界检测 (Knowledge Boundary Detection)

**场景**：判断问题是否在 LLM 的知识范围内

```
用户问题: "2025年1月的美股行情怎么样？"
          │
          ▼
┌─────────────────────┐
│  Knowledge Boundary │
│  Detector (BERT)    │
└──────────┬──────────┘
           │
┌──────────┼──────────┬──────────┐
▼          ▼          ▼          ▼
时效性    专业性      地域性
0.95 ⚠️   0.72       0.45
    │
    └──────────────────┐
                       ▼
    时效性要求高 → 触发 RAG 或 Web Search
```

**分类标签**：
- 通用知识 (LLM 可直接回答)
- 时效性知识 (需要搜索/RAG)
- 专业知识 (需要专家模型)
- 个人知识 (需要用户补充)
- 超出能力 (诚实拒绝)

**价值**：让系统更「诚实」，减少幻觉，智能触发 RAG

---

### 8. 主题切换检测 (Topic Shift Detection)

**场景**：检测用户是否切换了话题

```
历史对话: 讨论 Python 编程
当前输入: "对了，明天北京天气怎么样？"
          │
          ▼
┌─────────────────────┐
│  Topic Shift        │
│  Detector (BERT)    │
│  句子对分类任务      │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│  主题一致性: 0.12   │
│  判定: 主题切换 ✅   │
└──────────┬──────────┘
           │
           ▼
触发动作:
• 清理/压缩无关历史上下文
• 重新评估路由 (编程→天气)
• 可能触发不同的工具 (天气 API)
```

**输入格式**：`[历史主题摘要] [SEP] [当前输入]`
**输出**：延续(0) / 相关切换(1) / 完全切换(2)

**价值**：优化上下文管理，提升多主题对话效率

---

### 9. 答案可信度评估 (Answer Confidence Scoring)

**场景**：评估 LLM 回答的可信度

```
评估维度:
┌────────────┐ ┌────────────┐ ┌────────────┐
│ 事实准确性 │ │ 逻辑一致性 │ │ 来源可靠性 │
│   0.85    │ │   0.92    │ │   0.78    │
└────────────┘ └────────────┘ └────────────┘
                    │
                    ▼
          综合可信度: 0.85
          ────────────────
          > 0.9: 直接返回
          0.7-0.9: 添加免责声明
          < 0.7: 触发 RAG 验证或人工审核
```

**价值**：自动化质量把关，与现有 Hallucination 检测结合

---

### 10. 代码理解与分类 (Code Understanding & Classification)

**场景**：针对代码相关请求的专门处理

```
用户输入包含代码:
"这段代码有什么问题？
 def foo(x):
     return x / 0"
          │
          ▼
┌─────────────────────┐
│  Code Classifier    │
│  (CodeBERT)         │
└──────────┬──────────┘
           │
┌──────────┼──────────┬──────────┬──────────┐
▼          ▼          ▼          ▼          ▼
语言      任务        难度       安全       领域
Python    Debug       简单       安全       通用
           │
           ▼
路由决策:
• 任务=Debug + 难度=简单 → 路由到快速模型
• 任务=架构设计 + 难度=复杂 → 路由到强推理模型
• 安全=可疑代码 → 触发安全审查
```

**价值**：针对编程场景优化路由

---

## 优先级建议

| 优先级 | 任务 | 输出头类型 | 价值 | 实现难度 |
|:------:|------|-----------|------|:--------:|
| ⭐⭐⭐⭐⭐ | **知识边界检测** | 序列分类 | 减少幻觉，智能触发 RAG | 中 |
| ⭐⭐⭐⭐⭐ | **响应质量评估** | 多标签分类/回归 | 自动质量把关 | 中 |
| ⭐⭐⭐⭐ | **主题切换检测** | 句子对分类 | 优化上下文管理 | 低 |
| ⭐⭐⭐⭐ | **查询改写/扩展** | 分类+模板 | 提升 LLM 回答质量 | 中 |
| ⭐⭐⭐⭐ | **多轮意图追踪** | 序列分类+Token分类 | 精准路由 | 高 |
| ⭐⭐⭐ | **毒性/情感检测** | 多标签分类 | 完善安全体系 | 低 |
| ⭐⭐⭐ | **提示词质量评估** | 多标签分类 | 主动引导用户 | 低 |
| ⭐⭐⭐ | **语义压缩** | 回归+Token分类 | 突破上下文限制 | 高 |
| ⭐⭐ | **代码理解** | 多任务分类 | 编程场景优化 | 中 |
| ⭐⭐ | **答案可信度** | 回归 | 多维质量评估 | 中 |

---

## 快速见效的「低垂果实」

### 1. 知识边界检测
- 与现有 RAG 插件联动
- 训练数据：可从现有问答数据集构造
- 输出：是否需要外部知识 (二分类)

### 2. 主题切换检测
- 极简实现：复用现有嵌入模型计算句子相似度
- 进阶实现：训练句子对分类器
- 与现有 semantic-cache 协同

### 3. 毒性检测
- 与现有 Jailbreak 检测架构完全一致
- 大量公开数据集可用 (Jigsaw, Civil Comments)
- 可复用现有训练 pipeline

---

## 附录：BERT 应用全景图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        BERT 应用全景图                                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   ✅ 已实现                              ❓ 待挖掘                           │
│   ─────────                              ─────────                          │
│   • 意图/领域分类                         • 查询改写/扩展                      │
│   • PII 检测 (NER)                       • 提示词质量评估                      │
│   • Jailbreak 检测                       • 响应质量评估                       │
│   • 用户满意度分类                        • 语义压缩/去重                      │
│   • 事实核查需求检测                      • 多轮对话理解                       │
│   • 语义嵌入/相似度                       • 毒性/情感检测                      │
│   • 幻觉检测                             • 知识边界检测                       │
│                                          • 主题切换检测                       │
│                                          • 答案可信度评估                      │
│                                          • 代码理解与分类                      │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

*文档生成时间: 2026-02-03*
