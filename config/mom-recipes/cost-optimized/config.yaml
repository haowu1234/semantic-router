# Cost-Optimized MoM Recipe
# 60%+ token reduction through size-aware routing and aggressive caching
#
# Usage: vllm-sr serve --config config/mom-recipes/cost-optimized/config.yaml

# Response API
response_api:
  enabled: true
  store_backend: "memory"
  ttl_seconds: 7200
  max_responses: 2000

# Semantic Cache - Aggressive caching
semantic_cache:
  enabled: true
  backend_type: "memory"
  similarity_threshold: 0.75  # Low threshold for more cache hits
  max_entries: 50000  # Large cache
  ttl_seconds: 7200  # Long TTL
  eviction_policy: "lru"
  use_hnsw: true
  hnsw_m: 32
  hnsw_ef_construction: 100
  embedding_model: "bert"  # Fast embeddings

# Tools - Disabled
tools:
  enabled: false

# Prompt Guard - Minimal
prompt_guard:
  enabled: true
  threshold: 0.9
  use_cpu: true

# Classifier
classifier:
  category_model:
    model_id: "models/mom-domain-classifier"
    threshold: 0.5
    use_cpu: true

# Hallucination - Disabled for cost
hallucination_mitigation:
  enabled: false

# vLLM Endpoints
vllm_endpoints:
  - name: "endpoint-small"
    address: "127.0.0.1"
    port: 8001
    weight: 3  # Higher weight for small model
  - name: "endpoint-medium"
    address: "127.0.0.1"
    port: 8002
    weight: 1

# Model Configuration
model_config:
  "qwen3-small":
    reasoning_family: "qwen3"
    preferred_endpoints: ["endpoint-small"]
  "qwen3-medium":
    reasoning_family: "qwen3"
    preferred_endpoints: ["endpoint-medium"]

# Categories
categories:
  - name: simple
    description: "Simple queries"
    mmlu_categories: ["other"]
  - name: complex
    description: "Complex queries"
    mmlu_categories: ["math", "physics", "chemistry"]

strategy: "priority"

# Cost-optimized decisions
decisions:
  - name: "simple_decision"
    description: "Simple queries - small model"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "simple"
    modelRefs:
      - model: "qwen3-small"
        use_reasoning: false
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "Be brief. Maximum 100 words."
      - type: "semantic-cache"
        configuration:
          enabled: true
          similarity_threshold: 0.75

  - name: "complex_decision"
    description: "Complex queries - medium model"
    priority: 50
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "complex"
    modelRefs:
      - model: "qwen3-medium"
        use_reasoning: false
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "Be concise but accurate. Maximum 200 words."
      - type: "semantic-cache"
        configuration:
          enabled: true
          similarity_threshold: 0.80

default_model: qwen3-small

reasoning_families:
  qwen3:
    type: "chat_template_kwargs"
    parameter: "enable_thinking"

default_reasoning_effort: low

# Router
router:
  high_confidence_threshold: 0.6
  low_latency_threshold_ms: 1000
  default_max_latency_ms: 2000

# API
api:
  batch_classification:
    max_batch_size: 200
    max_concurrency: 16

# Embedding
embedding_models:
  qwen3_model_path: "models/mom-embedding-flash"
  use_cpu: true

# Observability
observability:
  metrics:
    enabled: true
  tracing:
    enabled: false
